{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Deglitching\n",
    "###### Samuel Wallace\n",
    "\n",
    "Here is a program to interactively test parameters for the deglitching algorithm. It uses the bokeh and ipywidgets packages and requires nodejs. *If you're having trouble in JupyterLab, please see this.*\n",
    "\n",
    "The first cell imports the packages you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"4785\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"4785\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"4785\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"4785\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"4785\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from bokeh.io import curdoc, output_notebook\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import ColumnDataSource, Slider, RadioButtonGroup, Button, LinearAxis, Select\n",
    "from bokeh.models.ranges import Range1d\n",
    "from bokeh.plotting import figure, show\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "import larch\n",
    "from larch_plugins.utils import group2dict\n",
    "from larch_plugins.xafs import autobk, pre_edge\n",
    "from larch import Interpreter, Group\n",
    "session=Interpreter(with_plugins=False)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data here\n",
    "\n",
    "You may also set parameters for pre edge and autobk functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join('dat_001.dat')\n",
    "\n",
    "dat    = Group()\n",
    "raw_dat= np.loadtxt(fpath).T\n",
    "\n",
    "energy = raw_dat[0]\n",
    "fluo   = raw_dat[16]\n",
    "\n",
    "setattr(dat, 'energy', energy)\n",
    "setattr(dat, 'fluo', fluo)\n",
    "\n",
    "pre_edge_kws = {}\n",
    "autobk_kws = {'kw':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the deglitching functions; the `deglitching` function itself is modified to emphasize the most important parameters for full-spectrum deglitching and to plot the intermediate calculations. The final cell shows the interactive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def genesd(data, max_outliers, alpha):\n",
    "    \"\"\"Routine to identify outliers from normally-distributed data set.\n",
    "\n",
    "    Utilizes the generalized extreme Studentized deviate test for outliers to identify indices in an array that correspond to outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        Array containing the data to perform the genESD routine.\n",
    "    max_outliers : int\n",
    "        Maximum number of outliers to remove.\n",
    "    alpha : float\n",
    "        alpha value for statistical test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    indexOutliers : group\n",
    "        indices of outliers in the data.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # copy of original data\n",
    "    cpdata       = np.copy(data)\n",
    "    \n",
    "    # containers for data\n",
    "    rivals         = []    # Ri values\n",
    "    critvals       = []    # critical values\n",
    "    outliers       = []    # outliers\n",
    "    \n",
    "    for i in range(max_outliers):\n",
    "        ri, outlier = find_ri(cpdata)\n",
    "        \n",
    "        outliers.append(cpdata[outlier])\n",
    "        #removing outlier before calculating critical values\n",
    "        cpdata    = np.delete(cpdata, outlier)\n",
    "        critval   = find_critval(cpdata, alpha)\n",
    "\n",
    "        # appending values to containers\n",
    "        rivals.append(ri)\n",
    "        critvals.append(critval)\n",
    "\n",
    "    # at the highest value where Ri > critical value, that is the number of outliers\n",
    "    j = 0\n",
    "    i = 0\n",
    "    while j < len(rivals):\n",
    "        if rivals[j] > critvals[j]:\n",
    "            i = j + 1\n",
    "        j += 1\n",
    "    outliers = outliers[:i]\n",
    "    \n",
    "    # returning outliers indices in the original data\n",
    "    outliers_index = [i for i,elem in enumerate(data) if elem in outliers]\n",
    "\n",
    "    return (np.array(outliers_index))\n",
    "\n",
    "\n",
    "def find_ri(data):\n",
    "    \"\"\"Calculates test statistic for genesd.\n",
    "\n",
    "    This function finds the value furthest from the mean in a dataset.\n",
    "    Ri is given in terms of sample standard deviations from the mean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        Array containing the data to perform the analysis.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ri : float\n",
    "        Test statistic for the generalized extreme Studentized deviate test.\n",
    "\n",
    "    max_index : float\n",
    "        The index corresponding to the data point furthest from the mean.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # calculating mean and std of data\n",
    "    mean = np.mean(data)\n",
    "    std  = np.std(data, ddof=1)\n",
    "    \n",
    "    # obtaining index for residual maximum\n",
    "    residuals = np.absolute(data - mean)\n",
    "    max_index = np.argmax(residuals)\n",
    "    max_obs   = residuals[max_index]\n",
    "    ri        = max_obs/std\n",
    "    \n",
    "    return (ri, max_index)\n",
    "\n",
    "\n",
    "def find_critval(data, alpha):\n",
    "    \"\"\"Finds critical values for the genesd function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        Array containing the data to perform the analysis.\n",
    "    alpha : float\n",
    "        Significance level.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    critval : float\n",
    "        Returns the critical value for comparison with the test statistic Ri.\n",
    "    \"\"\"\n",
    "    from scipy.stats import t\n",
    "    \n",
    "    n    = len(data)\n",
    "    p    = 1 - ( alpha / ( 2 * (n + 1) ) )\n",
    "    \n",
    "    # finds t value corresponding to probability that \n",
    "    # sample within data set is itself an outlying point\n",
    "    tval    = t.ppf(p, n-1) \n",
    "    critval = (n * tval) / ( ( (n - 1 + (tval**2)) * (n + 1) )**(1/2) )\n",
    "    return (critval)\n",
    "\n",
    "\n",
    "def roll_med(data, window, min_samples=2, edgemethod='nan'):\n",
    "    \"\"\"Rolling median calculation, also known as a median filter.\n",
    "\n",
    "    Ignores nan values and calculates the median for a moving window.\n",
    "    Results are returned in the index corresponding to the center of the window.\n",
    "    This offers the option of forcing a median calculation even with an abbreviated window\n",
    "    and automatically skips nan values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array\n",
    "        Array containing the data.\n",
    "    window : odd int\n",
    "        Size of the rolling window for analysis.\n",
    "    min_samples: int\n",
    "        Minimum samples needed to calculate MAD. If the number of datapoints\n",
    "        in the window is less than min_samples, np.nan is given as the MAD at\n",
    "        that index.\n",
    "    edgemethod : {'nan','calc','extend'}\n",
    "        Dictates how standard deviation at the edge of the dataset is calculated\n",
    "        'nan' inserts np.nan values for each point where the window cannot be centered on the analyzed point. \n",
    "        'calc' calculates standard deviation with an abbreviated window at the edges (e.g. the first sample will have (window/2)+1 points in the calculation).\n",
    "        'extend' uses the nearest calculated value for the points at the edge of the data.\n",
    "    Returns\n",
    "    -------\n",
    "    stddev : array\n",
    "        Array with standard deviation found for each point centered in the window.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    if window%2 == 0:\n",
    "        raise ValueError('Please choose an odd value for the window length.')\n",
    "    elif window < 3 or type(window)!=int:\n",
    "        raise ValueError('Please select an odd integer value of at least 3 for the window length.')\n",
    "\n",
    "    validEdgeMethods = ['nan', 'extend', 'calc'] \n",
    "    \n",
    "    if edgemethod not in validEdgeMethods:\n",
    "        raise ValueError('Please choose a valid edge method: '+ validEdgeMethods)\n",
    "\n",
    "    movement  = int((window - 1) / 2) #how many points on either side of the point of interest are included in the window?\n",
    "    med_array = np.array([np.nan for point in data])\n",
    "    for i, point in enumerate(data[ : -movement]):\n",
    "        if i>=movement:\n",
    "            if np.count_nonzero(np.isnan(data[i - movement : i + 1 + movement]) == False) >= min_samples:\n",
    "                med_array[i]  =   np.nanmedian(data[i - movement : i + 1 + movement])\n",
    "    if edgemethod == 'nan':\n",
    "        return med_array\n",
    "    for i, point in enumerate(data[ : movement]):\n",
    "        if edgemethod == 'calc':\n",
    "            if np.count_nonzero(np.isnan(data[0 : i + 1 + movement]) == False) >= min_samples:\n",
    "                med_array[i]  =   np.nanmedian(data[0 : i + 1 + movement])\n",
    "        if edgemethod == 'extend':\n",
    "            med_array[i] = med_array[movement]\n",
    "    for i, point in enumerate(data[-movement : ]):\n",
    "        if edgemethod == 'calc':\n",
    "            if np.count_nonzero(np.isnan(data[(-2 * movement) + i : ]) == False) >= min_samples:\n",
    "                med_array[-movement + i] = np.nanmedian(data[(-2 * movement) + i : ])\n",
    "        if edgemethod == 'extend':\n",
    "            med_array[-movement + i] = med_array[-movement - 1]\n",
    "   \n",
    "    return med_array\n",
    "\n",
    "def deglitch(energy, mu, group, e_window='xas', sg_window_length=9, sg_polyorder=3, \n",
    "             alpha=.025, max_glitches='Default', max_glitch_length=4, bypass_interpolation=False, plot_res=False,\n",
    "            update=False):\n",
    "    \"\"\"Routine to deglitch a XAS spectrum.\n",
    "\n",
    "    This function deglitches points in XAS data through two-step \n",
    "    fitting with Savitzky-Golay filter and outlier identification \n",
    "    with generalized extreme student deviate test.\n",
    "\n",
    "    This code requires the data group to have at least an energy \n",
    "    and absorption channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    energy : array\n",
    "        Array of the energies of the XAS scan\n",
    "    mu : array\n",
    "        Array of the absorption coefficient data\n",
    "    group : Araucaria Group\n",
    "        Group to be modified by deglitching procedure\n",
    "    e_window : {'xas', 'xanes', 'exafs', (float, float)}\n",
    "        'xas' scans the full spectrum.\n",
    "        'xanes' looks from the beginning up to the edge + 150eV.\n",
    "        'exafs' looks at the edge + 150eV to the end.\n",
    "        (float, float) provides start and end energies in eV for analysis\n",
    "    sg_window_length : odd int, default: 7\n",
    "        Window length to build Savitzky-Golay filter from normalized data\n",
    "    sg_polyorder : int, default: 3\n",
    "        Polynomial order to build Savitzky-Golay filter from normalized data\n",
    "    alpha : float, default: .001\n",
    "        Alpha value for generalized ESD test for outliers.\n",
    "    max_glitches : int, default: len(data)//10\n",
    "        Maximum number of outliers to remove.\n",
    "    bypass_interpolation : bool, default: False\n",
    "        Bool for bypassing the interpolation safeguard in glitch identification.\n",
    "        Setting to True will increase the incidence of Type I errors and should\n",
    "        only be done in limited circumstances (e.g. extensive glitches in EXAFS\n",
    "        region) and with greater supervision.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import interp1d\n",
    "    from scipy.signal import savgol_filter\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    # computing the energy window to perform the deglitch:\n",
    "    \n",
    "    # creating copies of original data\n",
    "    mu_copy = np.copy(mu)   # interpolated values for posterior analysis will be inserted in this \n",
    "    ener    = np.copy(energy) # copy of energy to create interp1d function without the potential glitches\n",
    "    \n",
    "    # not limited to start:end to ensure data at edges gets best possible fit\n",
    "    sg_init = savgol_filter(mu, sg_window_length, sg_polyorder) \n",
    "\n",
    "    # computing the difference between normalized spectrum and the savitsky-golay filter\n",
    "    res1      = mu - sg_init\n",
    "    roll_mad1 = roll_med(abs(res1), window = 2*(sg_window_length+(max_glitch_length-1))+1, edgemethod='calc')\n",
    "    res_norm  = res1 / roll_mad1\n",
    "    \n",
    "    max_glitches = len(res1)//10\n",
    "    out1 = genesd(res_norm, max_glitches, alpha) #finds outliers in residuals between data and Savitzky-Golay filter\n",
    "    \n",
    "    if len(out1) == 0: #deglitching ends here if no outliers are found in this first round of analysis\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        e2         = np.delete(ener, out1) #removes points that are poorly fitted by the S-G filter\n",
    "        n2         = np.delete(mu_copy, out1)\n",
    "        f          = interp1d(e2, n2, kind='cubic') \n",
    "        interp_pts = f(energy[out1]) #interpolates for normalized mu at the removed energies\n",
    "\n",
    "        for i, point in enumerate(out1):\n",
    "            mu_copy[point] = interp_pts[i] #inserts interpolated points into normalized data\n",
    "\n",
    "        sg_final  = savgol_filter(mu_copy, sg_window_length, sg_polyorder) #fits the normalized absorption with the interpolated points\n",
    "        res2      = mu - sg_final\n",
    "        roll_mad2 = roll_med(abs(res2), window = (2*max_glitch_length)+1, edgemethod='calc')\n",
    "        res_norm2 = res2 / roll_mad2\n",
    "\n",
    "        glitches_init = genesd(res_norm2, max_glitches, alpha)#by normalizing the standard deviation to the same window as our S-G calculation, \n",
    "            #we can tackle the full spectrum, accounting for the noise we expect in the data;\n",
    "            #as a bonus, with the S-G filter, we ideally have a near-normal distribution of residuals\n",
    "            #(which makes the generalized ESD a robust method for finding the outliers)\n",
    "\n",
    "    \n",
    "    glitches = np.array([])\n",
    "    for glitch in glitches_init:\n",
    "        if True in np.where(abs(glitch-out1) < (sg_window_length//2) + 1, True, False):\n",
    "            glitches = np.append(glitches, glitch)\n",
    "    glitches[::-1].sort()\n",
    "    glitches = glitches.astype(int)\n",
    "    \n",
    "    if update:\n",
    "        data_filt  = deepcopy(group) #non-destructive copy for comparison\n",
    "        group_dict = data_filt.__dict__ #transfers data copy to a dictionary (easier to work with)\n",
    "\n",
    "        if len(glitches) == 0:\n",
    "            glitches = None\n",
    "\n",
    "        else:\n",
    "            glitch_dict = {energy[glitch] : {} for glitch in glitches}\n",
    "            for number in glitches:\n",
    "                targetLength = len(energy) #everything that is of the same length as the energy array will have the indices\n",
    "                                                #corresponding to glitches removed\n",
    "                for key in dir(group):\n",
    "                    if type(getattr(group, key)) == np.ndarray or type(getattr(group, key)) == list:\n",
    "                        if len(getattr(group, key)) == targetLength and key!='energy': #deletes the energy last\n",
    "                            glitch_dict[getattr(group, 'energy')[number]].update({key : group_dict[key][number]})\n",
    "                            group_dict[key] = np.delete(group_dict[key], number) #replaces the array with one that removes glitch points\n",
    "                            #numpy arrays require extra steps to delete an element (which is why this takes this structure)\n",
    "                            #removed indices is reversed to avoid changing the length ahead of the removal of points\n",
    "\n",
    "                group_dict['energy'] = np.delete(group_dict['energy'], number)\n",
    "\n",
    "                glitch_dict[energy[number]].update({'params' : {'e_window':e_window,\n",
    "                                                                'sg_window_length':sg_window_length, \n",
    "                                                                'sg_polyorder':sg_polyorder,\n",
    "                                                                'alpha':alpha,\n",
    "                                                                'max_glitches':max_glitches,\n",
    "                                                                'max_glitch_length':max_glitch_length\n",
    "                                                               }\n",
    "                                                   })\n",
    "        if glitches is not None:\n",
    "            if hasattr(group,'glitches'):\n",
    "                group_dict['glitches'].update(glitch_dict)\n",
    "            else:\n",
    "                setattr(group,'glitches', glitch_dict)\n",
    "\n",
    "        dataKeys = list(group_dict.keys())\n",
    "        for item in dataKeys:\n",
    "            setattr(group, item, group_dict[item])\n",
    "        \n",
    "    candidates = [energy[out1], mu[out1], interp_pts]\n",
    "    glitches   = [energy[glitches], mu[glitches]]\n",
    "    sg_filters = [sg_init, sg_final]\n",
    "    resids     = [res1, res2]\n",
    "    norm_res   = [res_norm, res_norm2]\n",
    "    return(candidates, glitches, sg_filters, resids, norm_res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def deglitch_plot(doc):\n",
    "    # Set up plot\n",
    "    plot = figure(height=600, width=900, tools=\"crosshair,pan,reset,wheel_zoom, box_zoom\")\n",
    "    deglitch_results = deglitch(dat.energy, dat.fluo, group=dat, sg_window_length=9, alpha=.025, max_glitch_length=4)\n",
    "    candidates, glitches, sg_filters, resids, norm_res = deglitch_results\n",
    "    \n",
    "    res_plot = figure(height=600, width=900, tools=\"crosshair,pan,reset,wheel_zoom, box_zoom\")\n",
    "    plot_dat = {'energy':energy, 'mu':fluo, \n",
    "                'sg_i':sg_filters[0], 'sg_f':sg_filters[1],\n",
    "                'res_1': resids[0], 'res_2':resids[1],\n",
    "                'res_norm_1':norm_res[0], 'res_norm_2':norm_res[1],\n",
    "                'sg_plot':sg_filters[0], 'res_plot':resids[0], \n",
    "                'res_norm_plot':norm_res[0], 'index':np.array(range(len(energy)))\n",
    "               }\n",
    "    #setting up the data for the different plots\n",
    "    cand_dat   = {'cand_e':candidates[0], 'cand_mu':candidates[1], 'interp':candidates[2]}\n",
    "    glitch_dat = {'glitch_e':glitches[0], 'glitch_mu':glitches[1]}\n",
    "    \n",
    "    full_source = ColumnDataSource(data=plot_dat)\n",
    "    cand_source = ColumnDataSource(data=cand_dat)\n",
    "    glit_source = ColumnDataSource(data=glitch_dat)\n",
    "    \n",
    "    res_plot.yaxis.axis_label = 'Residual Value'\n",
    "    res_plot.xaxis.axis_label = 'Point Index'\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plotting the data\n",
    "    res_plot.y_range = Range1d(-60*scipy.stats.iqr(full_source.data['res_plot']), 60*scipy.stats.iqr(full_source.data['res_plot']))\n",
    "    res_plot.circle('index', 'res_plot', source=full_source, size=2, color='purple', legend_label='Residuals')\n",
    "    res_plot.extra_y_ranges = {\"Normalized\": Range1d(start=-60*scipy.stats.iqr(full_source.data['res_norm_plot']), end=60*scipy.stats.iqr(full_source.data['res_norm_plot']))}\n",
    "    res_plot.add_layout(LinearAxis(y_range_name=\"Normalized\", axis_label='Normliazed Residual Value'), 'right')\n",
    "    res_plot.square('index', 'res_norm_plot', source=full_source, y_range_name='Normalized',size=2, color='orange', legend_label='Normalized Residuals')\n",
    "    res_plot.legend.click_policy=\"hide\"\n",
    "\n",
    "    plot.line('energy', 'mu', source=full_source, line_alpha=0.95, line_width = 2, legend_label='Original Data')\n",
    "    plot.line('energy', 'sg_plot', source=full_source, line_alpha=0.75, line_width=1.5,  color='green', legend_label='Savitzky-Golay Filter')\n",
    "    plot.circle('energy', 'res_plot', source=full_source, size=2, color='purple', legend_label='Residuals')\n",
    "    \n",
    "    plot.diamond('cand_e', 'cand_mu', source=cand_source, fill_color='gold', line_color='gray', legend_label='Candidate Points', size=7)\n",
    "    plot.circle('cand_e', 'interp', source=cand_source, line_width=2, color='gray', legend_label='Interpolated Points')\n",
    "    \n",
    "    plot.x('glitch_e', 'glitch_mu', source=glit_source, line_width=1.5, size=7, color='red', legend_label='Glitches')\n",
    "\n",
    "    \n",
    "    plot.legend.location = \"top_right\"\n",
    "    plot.legend.click_policy=\"hide\"\n",
    "\n",
    "    # setting up the widgets\n",
    "    alpha  = Slider(title=\"Alpha\", value=0.025, start=.005, end=0.500, step=.005, format='0[.]000')\n",
    "    sg_len = Slider(title=\"Filter Window Length\", value=9, start=5, end=31, step=2)\n",
    "    g_len  = Slider(title=\"Max Glitch Length\", value=4, start=1, end=11, step=1)\n",
    "    offset = Slider(title=\"Offset\", value=0, start=0, end=1, step=0.01)\n",
    "    pass_n = RadioButtonGroup(labels=['First Pass', 'Second Pass'], active=0)\n",
    "    plot_select = Select(options=['Absorption', 'Residuals', 'Histogram', 'EXAFS'], value='Absorption')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Set up functions for widgets\n",
    "    def update_offset(attrname, old, new):\n",
    "        shift = offset.value\n",
    "        #only for visualization purposes\n",
    "        full_source.data['sg_plot'] = sg_filters[pass_n.active] - shift\n",
    "        full_source.data['res_plot'] = resids[pass_n.active] + shift\n",
    "        \n",
    "    def update_data(attrname, old, new):\n",
    "\n",
    "        # Get the current slider values        \n",
    "        sg = sg_len.value\n",
    "        al = alpha.value\n",
    "        g  = g_len.value\n",
    "        pass_index = pass_n.active\n",
    "        \n",
    "        #deglitch with the new values\n",
    "        \n",
    "        #will not run autobk unless you're actively looking at that plot\n",
    "        if plot_select.value=='EXAFS':\n",
    "            new_dat = deepcopy(dat)\n",
    "            deglitch_results = deglitch(new_dat.energy, new_dat.fluo, group=new_dat, sg_window_length=sg,\n",
    "                                        alpha=al, max_glitch_length=g, update=True)\n",
    "            pre_edge(new_dat.energy, new_dat.fluo, group=new_dat, _larch=session, **pre_edge_kws)\n",
    "            autobk(new_dat.energy, new_dat.fluo, group=new_dat, _larch=session, **autobk_kws)\n",
    "            ksource.data['new_k2chi'] = (new_dat.k**2) * new_dat.chi\n",
    "        \n",
    "        deglitch_results = deglitch(dat.energy, dat.fluo, group=dat, sg_window_length=sg, alpha=al, max_glitch_length=g)\n",
    "        candidates, glitches, sg_filters, resids, norm_res = deglitch_results\n",
    "        \n",
    "        \n",
    "        hist, edges = np.histogram(norm_res[pass_index], bins='auto')\n",
    "        #update the data\n",
    "        plot_dat = {'energy':energy, 'mu':fluo, \n",
    "                    'sg_i':sg_filters[0], 'sg_f':sg_filters[1],\n",
    "                    'res_1': resids[0], 'res_2':resids[1],\n",
    "                    'res_norm_1':norm_res[0], 'res_norm_2':norm_res[1],\n",
    "                    'sg_plot':sg_filters[pass_index] - offset.value, \n",
    "                    'res_plot':resids[pass_index] + offset.value,\n",
    "                    'res_norm_plot':norm_res[pass_index], 'index':np.array(range(len(energy)))\n",
    "                   }\n",
    "\n",
    "        \n",
    "        cand_dat   = {'cand_e':candidates[0], 'cand_mu':candidates[1], 'interp':candidates[2]}\n",
    "        glitch_dat = {'glitch_e':glitches[0], 'glitch_mu':glitches[1]}\n",
    "        hist_dat = {'hist':hist, 'left':edges[:-1], 'right':edges[1:]}\n",
    "        \n",
    "        hist_source.data = hist_dat\n",
    "        full_source.data = plot_dat\n",
    "        cand_source.data = cand_dat\n",
    "        glit_source.data = glitch_dat\n",
    "            \n",
    "\n",
    "        \n",
    "    hist, edges = np.histogram(full_source.data['res_norm_plot'], bins='auto')\n",
    "    hist_dat = {'hist':hist, 'left':edges[:-1], 'right':edges[1:]}\n",
    "    hist_source = ColumnDataSource(data=hist_dat)\n",
    "    hist_plot = figure(height=600, width=900, tools=\"crosshair,pan,reset,wheel_zoom, box_zoom\")\n",
    "    hist_plot.quad(top='hist', bottom=0, left='left', right='right', color='orange', source=hist_source)\n",
    "    hist_plot.yaxis.axis_label='Data Points'\n",
    "    hist_plot.yaxis.axis_label='Norm. Resid. Value'\n",
    "\n",
    "    pre_edge(dat.energy, dat.fluo, group=dat, _larch=session, **pre_edge_kws)\n",
    "    autobk(dat.energy, dat.fluo, group=dat, _larch=session, **autobk_kws)\n",
    "    \n",
    "    k_plot = figure(height=600, width=900, tools=\"crosshair,pan,reset,wheel_zoom, box_zoom\")\n",
    "    k_data   ={'k'         : dat.k,\n",
    "               'k2chi'     : (dat.k**2) * dat.chi, \n",
    "               'new_k2chi' : (dat.k**2) * dat.chi, \n",
    "              }\n",
    "    ksource=ColumnDataSource(k_data)\n",
    "    k_plot.line('k', 'k2chi', legend_label='Original EXAFS', color='red', source=ksource)\n",
    "    k_plot.line('k', 'new_k2chi', legend_label='Deglitched EXAFS', color='black', source=ksource)\n",
    "    k_plot.xaxis.axis_label = 'k (Å⁻¹)'\n",
    "    k_plot.yaxis.axis_label = 'k²χ'\n",
    "    \n",
    "    def select_plot(attrname, old, new):\n",
    "        #selects the plot to show\n",
    "        new_plot = plot_select.value\n",
    "        #'Absorption', 'Residuals', 'Histogram', 'EXAFS'\n",
    "        if 'Abs' in new_plot:\n",
    "            active_plot = plot\n",
    "        elif 'Res' in new_plot:\n",
    "            active_plot = res_plot\n",
    "        elif 'Hist' in new_plot:\n",
    "            active_plot = hist_plot\n",
    "        else:\n",
    "            # NOTE: EXAFS plot does not update automatically here\n",
    "            # This is to save computer power, since this is to show the nimble nature of the deglitching algorithm\n",
    "            sg = sg_len.value\n",
    "            al = alpha.value\n",
    "            g  = g_len.value\n",
    "            pass_index = pass_n.active\n",
    "\n",
    "            new_dat = deepcopy(dat)\n",
    "            deglitch_results = deglitch(new_dat.energy, new_dat.fluo, group=new_dat, sg_window_length=sg,\n",
    "                                        alpha=al, max_glitch_length=g, update=True)\n",
    "\n",
    "            \n",
    "            pre_edge(new_dat.energy, new_dat.fluo, group=new_dat, _larch=session, **pre_edge_kws)\n",
    "            autobk(new_dat.energy, new_dat.fluo, group=new_dat, _larch=session, **autobk_kws)\n",
    "    \n",
    "\n",
    "            ksource.data['new_k2chi'] = (new_dat.k**2) * new_dat.chi\n",
    "            active_plot = k_plot\n",
    "            \n",
    "        doc.remove_root(doc.roots[0])\n",
    "        doc.add_root(row(inputs, active_plot))\n",
    "    \n",
    "    for w in [sg_len, alpha, g_len]:\n",
    "        w.on_change('value', update_data)\n",
    "    offset.on_change('value', update_offset)\n",
    "    \n",
    "    \n",
    "    pass_n.on_change('active', update_data)\n",
    "    \n",
    "    plot_select.on_change('value', select_plot)\n",
    "    # Set up layouts and add to document\n",
    "    inputs = column(plot_select, pass_n, alpha, sg_len, g_len, offset)\n",
    "\n",
    "    doc.add_root(row(inputs, plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bokeh.server.server:Starting Bokeh server version 2.3.3 (running on Tornado 6.0.4)\n",
      "INFO:bokeh.server.tornado:User authentication hooks NOT provided (default user enabled)\n"
     ]
    },
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script id=\"7387\">\n",
       "  var xhr = new XMLHttpRequest()\n",
       "  xhr.responseType = 'blob';\n",
       "  xhr.open('GET', \"http://localhost:51382/autoload.js?bokeh-autoload-element=7387&bokeh-absolute-url=http://localhost:51382&resources=none\", true);\n",
       "  \n",
       "  xhr.onload = function (event) {\n",
       "    var script = document.createElement('script'),\n",
       "    src = URL.createObjectURL(event.target.response);\n",
       "    script.src = src;\n",
       "    document.body.appendChild(script);\n",
       "  };\n",
       "xhr.send();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "9cb1df4c0dd943c58a9ab935b6d6c351"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tornado.access] INFO : 200 GET /autoload.js?bokeh-autoload-element=7387&bokeh-absolute-url=http://localhost:51382&resources=none (127.0.0.1) 415.11ms\n",
      "[tornado.access] INFO : 101 GET /ws (127.0.0.1) 1.00ms\n",
      "INFO:bokeh.server.views.ws:WebSocket connection opened\n",
      "INFO:bokeh.server.views.ws:ServerConnection created\n"
     ]
    }
   ],
   "source": [
    "show(deglitch_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
